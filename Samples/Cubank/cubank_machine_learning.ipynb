{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:42px; text-align:center; margin-bottom:30px;\"><span style=\"color:SteelBlue\">Cubank:</span> Machine Learning with Python and TM1</h1><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "Before we get started, plotting libraries need to be imported. All the other dependencies we can import on the fly when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "\n",
    "py.init_notebook_mode()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Bring TM1 Data To Python\n",
    "\n",
    "-----\n",
    "\n",
    "## 1.1 Query TM1 cube data\n",
    "\n",
    "We use **TM1py** to query data from cube Loans through an **MDX** Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDRESS = \"localhost\"\n",
    "PORT = 5001\n",
    "USER = \"admin\"\n",
    "PWD = \"YXBwbGU=\"\n",
    "SSL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TM1py import TM1Service\n",
    "\n",
    "mdx = \"\"\"\n",
    "SELECT \n",
    "    NON EMPTY  \n",
    "    { HEAD ( {Tm1FilterByLevel ( {Tm1SubsetAll ([Loan])} , 0 ) } , 20000 ) }  * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([LC Rating])} , 0 ) } * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([FICO Score])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Purpose])} , 0 ) } * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([State])} , 0 ) } * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Income To Loan Ratio])} , 0 ) } * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Home Ownership])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Delinquency Events])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Time])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Income])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Application Type])} , 0 ) } *\n",
    "    {[Loan Status].[Fully Paid], [Loan Status].[Charged Off], [Loan Status].[default]}  ON ROWS,\n",
    "    {[Loans Measure].[loan_amnt], [Loans Measure].[defaulted], [Loans Measure].[int_rate],\n",
    "    [Loans Measure].[num_personal_inquiries], [Loans Measure].[inquiries_in_last_12m],\n",
    "    [Loans Measure].[mths_since_last_delinq], [Loans Measure].[mths_since_recent_bc_dlq], \n",
    "    [Loans Measure].[mths_since_recent_inq]} ON COLUMNS\n",
    "FROM [Loans]\n",
    "WHERE ([Employment].[Total Employment], [Term].[Total Term])\n",
    "\"\"\"\n",
    "\n",
    "with TM1Service(address=ADDRESS, port=PORT, user=USER, password=PWD, ssl=SSL, decode_b64=True) as tm1:\n",
    "    loans_raw = tm1.cubes.cells.execute_mdx_dataframe(mdx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loans_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the 5 sample records from our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessing\n",
    "\n",
    "Rearrange the dataframe into something that is more convenient for consumption\n",
    "\n",
    "- Arrange Measures as seperate columns\n",
    "\n",
    "- Remove Value Column\n",
    "\n",
    "- Set new index in DataFrame based on Loan-Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = loans_raw.copy()\n",
    "\n",
    "# Arrange measures as columns\n",
    "for measure in (\"defaulted\", \"loan_amnt\", \"num_personal_inquiries\", \"int_rate\",\n",
    "                \"inquiries_in_last_12m\", \"mths_since_last_delinq\", \"mths_since_recent_bc_dlq\",\n",
    "                \"mths_since_recent_inq\"):\n",
    "    loans[measure] = loans.apply(lambda row: row[\"Value\"] if row[\"Loans Measure\"] == measure else None, axis=1)\n",
    "\n",
    "loans.drop(columns=[\"Value\"], inplace=True)\n",
    "loans.drop(columns=[\"Loans Measure\"], inplace=True)\n",
    "\n",
    "columns_to_remain = [\"LC Rating\", \"FICO Score\", \"Purpose\", \"State\", \"Time\", \"Income\", \"Income To Loan Ratio\",\n",
    "                 \"Home Ownership\", \"Delinquency Events\", \"Application Type\"]\n",
    "\n",
    "loans = loans.groupby([\"Loan\"] + columns_to_remain).sum()\n",
    "\n",
    "for column in columns_to_remain:\n",
    "    loans.reset_index(level=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['defaulted'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Exploratory Data Analysis and Feature Selection\n",
    "\n",
    "-----\n",
    "\n",
    "We want to use pandas and plotly to \n",
    "\n",
    "- Get a high level overview of the dataset we are dealing with \n",
    "- Select relevant features and remove irrelavant features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 LC Rating\n",
    "\n",
    "Assigned loan grade by Lending Club\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"LC Rating\"].unique()),\n",
    "    y=loans.groupby(by=\"LC Rating\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Rating\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Purpose\n",
    "\n",
    "A category provided by the borrower for the loan request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"Purpose\"].unique()),\n",
    "    y=loans.groupby(by=\"Purpose\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Purpose\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 State\n",
    "\n",
    "The state provided by the borrower in the loan application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_by_state = loans.groupby(by=\"State\").mean()[\"defaulted\"] * 100\n",
    "loans_by_state.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Choropleth(\n",
    "    autocolorscale=True,\n",
    "    locations=loans_by_state.index,\n",
    "    z=loans_by_state.values,\n",
    "    locationmode='USA-states',\n",
    "    marker=go.choropleth.Marker(\n",
    "        line=go.choropleth.marker.Line(\n",
    "            color='rgb(255,255,255)',\n",
    "            width=2\n",
    "        )),\n",
    "    colorbar=go.choropleth.ColorBar(\n",
    "        title=\"Defaults in %\")\n",
    ")]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=go.layout.Title(\n",
    "        text='Percentage of Loans that default'\n",
    "    ),\n",
    "    geo=go.layout.Geo(\n",
    "        scope='usa',\n",
    "        projection=go.layout.geo.Projection(type='albers usa'),\n",
    "        showlakes=True,\n",
    "        lakecolor='rgb(255, 255, 255)'),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Income To Loan Ratio\n",
    "\n",
    "A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = loans.loc[loans['Income To Loan Ratio'] < 5]\n",
    "\n",
    "sum(df_temp[\"defaulted\"]) / len(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = loans.loc[loans['Income To Loan Ratio'] > 15]\n",
    "\n",
    "sum(df_temp[\"defaulted\"]) / len(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.groupby('defaulted')['Income To Loan Ratio'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Income\n",
    "\n",
    "The self-reported annual income provided by the borrower during registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"Income\"].unique()),\n",
    "    y=loans.groupby(by=\"Income\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Income\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loans.drop(\"Income\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Income is provided by the user. Seems unreliable. So we decide to remove it from the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Application Type\n",
    "\n",
    "Indicates whether the loan is an individual application or a joint application with two co-borrowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"Application Type\"].unique()),\n",
    "    y=loans.groupby(by=\"Application Type\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Income\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['Application Type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Time\n",
    "\n",
    "The month the loan was funded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loans['Time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.drop(\"Time\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 num_personal_inquiries\n",
    "\n",
    "Number of personal finance inquiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"num_personal_inquiries\"].unique()),\n",
    "    y=loans.groupby(by=\"num_personal_inquiries\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Number of Personal Finance Inquiries\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: More Data Processing\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate String columns to Numeric or Binary\n",
    "\n",
    "Unfortunately Classifier Implementation for python can only consume numeric **features**, so we need to translate string columns (e.g. State, Rating, purpose) into numeric and binary columns.\n",
    "\n",
    "**FROM**\n",
    "\n",
    "| Loan  | State  |\n",
    "| :-: | :-: |\n",
    "| Loan 5 | CA |\n",
    "| Loan 8 | WA |\n",
    "\n",
    "\n",
    "**TO**\n",
    "\n",
    "| Loan  | State_CA | State_WA |\n",
    "| :-: | :-: | :-: |\n",
    "| Loan 5 | 1 | 0 |\n",
    "| Loan 8 | 0 | 1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loans_numeric = pd.get_dummies(\n",
    "    loans, \n",
    "    columns=['LC Rating', 'Home Ownership', 'Purpose', 'State', 'Application Type'],\n",
    "    drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into **Features** (e.g. Income, Rating) and **Class** (Defaulted or Fully Paid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loans_numeric.loc[:, loans_numeric.columns != \"defaulted\"]\n",
    "y = loans_numeric[\"defaulted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation between columns and default\n",
    "\n",
    "Now that all columns are numeric values we can calculate Correlations between them\n",
    "\n",
    "- Values between 0 and 0.3 (0 and -0.3) indicate a weak positive (negative) linear relationship\n",
    "- Values between 0.3 and 0.7 (-0.3 and -0.7) indicate a moderate positive (negative) linear relationship\n",
    "- Values between 0.7 and 1.0 (-0.7 and -1.0) indicate a strong positive (negative) linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dep = pd.DataFrame()\n",
    "for col in X.columns:\n",
    "    linear_dep.loc[col, 'corr'] = X[col].corr(y)\n",
    "    \n",
    "linear_dep['abs_corr'] = abs(linear_dep['corr'])\n",
    "linear_dep.sort_values('abs_corr', ascending=False, inplace=True)\n",
    "\n",
    "linear_dep.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Fit And Evaluate Maschine Learning Model\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Scale data and split into test and training sets\n",
    "\n",
    "Before applying Machine Learning, we need to scale our data such that each feature has the same variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data set into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 KNN (K Nearest Neighbors)\n",
    "\n",
    "Fit KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply KNN model on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate KNN results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate confusion matrix from results on the test set and pretty-print visualization of confusion matrix as heatmap\n",
    "\n",
    "**Top Left** - True Positives: Loan default and we predicted default\n",
    "\n",
    "**Top Right** - False Negatives: Loan default and we predicted fine.\n",
    "\n",
    "**Bottom Left** - False Positive: Loan fine and we predicted default.\n",
    "\n",
    "**Bottom Right** - True Negatives: Loan fine and we predicted fine.\n",
    "\n",
    "Perfect precission would output a matrix with all values on the diagonal...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[1, 0])\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    matrix, \n",
    "    annot=True, \n",
    "    fmt='d',\n",
    "    linewidths=.5,\n",
    "    cmap=\"YlGnBu\");\n",
    "\n",
    "# labels and titles\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "ax.xaxis.set_ticklabels(['Defaulted', 'Fully Paid'])\n",
    "ax.yaxis.set_ticklabels(['Defaulted', 'Fully Paid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print classification report\n",
    "\n",
    "**precision** - What percent of the predicted defaults that were correct ?\n",
    "\n",
    "**recall** – What percent of the defaults did we catch ?\n",
    "\n",
    "**f1 score** – Weighted average over precission and recall\n",
    "\n",
    "**support** - number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "knn_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "probs = knn_classifier.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Random Forest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=20,\n",
    "    max_depth=100,\n",
    "    random_state=4)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prettyprint visualization of confusion matrix as heatmap\n",
    "\n",
    "**Top Left** - True Positives: Loan default and we predicted default\n",
    "\n",
    "**Top Right** - False Negatives: Loan default and we predicted fine.\n",
    "\n",
    "**Bottom Left** - False Positive: Loan fine and we predicted default.\n",
    "\n",
    "**Bottom Right** - True Negatives: Loan fine and we predicted fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "import seaborn as sns\n",
    "\n",
    "matrix = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[1, 0])\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    matrix, \n",
    "    annot=True, \n",
    "    fmt='d',\n",
    "    linewidths=.5,\n",
    "    cmap=\"YlGnBu\");\n",
    "\n",
    "# labels and titles\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "ax.xaxis.set_ticklabels(['Defaulted', 'Fully Paid'])\n",
    "ax.yaxis.set_ticklabels(['Defaulted', 'Fully Paid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print classification report\n",
    "\n",
    "**precision** - What percent of the predicted defaults that were correct ?\n",
    "\n",
    "**recall** – What percent of the defaults did we catch ?\n",
    "\n",
    "**f1 score** – Weighted average over precission and recall\n",
    "\n",
    "**support** - number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "probs = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_importances = pd.DataFrame(\n",
    "    rf_classifier.feature_importances_,\n",
    "    index = X.columns,\n",
    "    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other\n",
    "\n",
    "Things that didn't make it into the demo.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Home Ownership\n",
    "\n",
    "The home ownership status provided by the borrower during registration. \n",
    "\n",
    "Possible values are: RENT, OWN, MORTGAGE, OTHER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"Home Ownership\"].unique()),\n",
    "    y=loans.groupby(by=\"Home Ownership\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Home Ownership Type\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 FICO Score\n",
    "\n",
    "A credit score created by the Fair Isaac Corporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaulted = loans.loc[loans['defaulted'] == 1]['FICO Score']\n",
    "fine = loans.loc[loans['defaulted'] == 0]['FICO Score']\n",
    "\n",
    "hist1 = go.Histogram(\n",
    "    x=fine,\n",
    "    name=\"Fully Paid\"\n",
    ")\n",
    "hist2 = go.Histogram(\n",
    "    x=defaulted,\n",
    "    name=\"Defaulted\"\n",
    ")\n",
    "\n",
    "data = [hist1, hist2]\n",
    "layout = go.Layout(\n",
    "    barmode=\"stack\",\n",
    "    title=\"Histograms on FICO Score\")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "logrec_classifier = SGDClassifier(\n",
    "    loss='log', \n",
    "    max_iter=1000, \n",
    "    tol=1e-3, \n",
    "    random_state=1, \n",
    "    warm_start=True,\n",
    "    alpha=0.01, \n",
    "    penalty='l2')\n",
    "\n",
    "logrec_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logrec_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "matrix = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[1, 0])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print classification report\n",
    "\n",
    "**precision** - What percent of the predicted defaults that were correct ?\n",
    "\n",
    "**recall** – What percent of the defaults did we catch ?\n",
    "\n",
    "**f1 score** – Weighted average over precission and recall\n",
    "\n",
    "**support** - number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logrec_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "probs = logrec_classifier.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Dimension Reduction and Visualization in 2D\n",
    "\n",
    "_PCA is essentially a method that reduces the dimension of the feature space in such a way that new variables are orthogonal to each other (i.e. they are independent or not correlated)._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(X_train)\n",
    "principal_df = pd.DataFrame(\n",
    "    data = principal_components, \n",
    "    columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "    x = principal_df[\"principal component 1\"],\n",
    "    y = principal_df[\"principal component 2\"],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        color = y_train.values\n",
    "        ),\n",
    "    )]\n",
    "\n",
    "py.iplot(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
