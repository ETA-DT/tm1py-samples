{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:42px; text-align:center; margin-bottom:30px;\"><span style=\"color:SteelBlue\">Cubank:</span> Machine Learning with Python and TM1</h1><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "Before we get started, plotting libraries need to be imported. All the other dependencies we can import on the fly when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "\n",
    "py.init_notebook_mode()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Bring TM1 Data To Python\n",
    "\n",
    "-----\n",
    "\n",
    "## 1.1 Query TM1 cube data\n",
    "\n",
    "We use **TM1py** to query data from cube Loans through an **MDX** Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(r'..\\..\\config.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MDX query we are limiting the elements from the Loan dimension to the first 20k.\n",
    "\n",
    "While in the cube we have facts on > 1M loans, for this demo we will be using a reduced set of loans in order to assure that the succeeding steps (e.g. visualizations) will be fast.\n",
    "\n",
    "We will not query Loans that are still running. We want only loans that have a final state. Either `defaulted`, `charged off` or `fully paid`.\n",
    "\n",
    "We use the `execute_mdx_dataframe` method to build a dataframe from the result of the MDX query\n",
    "\n",
    "Then we store the results in the `loans_raw` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TM1py import TM1Service\n",
    "\n",
    "mdx = \"\"\"\n",
    "SELECT \n",
    "    NON EMPTY  \n",
    "    { HEAD ( {Tm1FilterByLevel ( {Tm1SubsetAll ([Loan])} , 0 ) } , 20000 ) }  * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([LC Rating])} , 0 ) } * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([FICO Score])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Purpose])} , 0 ) } * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([State])} , 0 ) } * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Income To Loan Ratio])} , 0 ) } * \n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Home Ownership])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Delinquency Events])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Time])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Income])} , 0 ) } *\n",
    "    {Tm1FilterByLevel ( {Tm1SubsetAll ([Application Type])} , 0 ) } *\n",
    "    {[Loan Status].[Fully Paid], [Loan Status].[Charged Off], [Loan Status].[default]}  ON ROWS,\n",
    "    {[Loans Measure].[loan_amnt], [Loans Measure].[defaulted], [Loans Measure].[int_rate],\n",
    "    [Loans Measure].[num_personal_inquiries], [Loans Measure].[inquiries_in_last_12m],\n",
    "    [Loans Measure].[mths_since_last_delinq], [Loans Measure].[mths_since_recent_bc_dlq], \n",
    "    [Loans Measure].[mths_since_recent_inq]} ON COLUMNS\n",
    "FROM [Loans]\n",
    "WHERE ([Employment].[Total Employment], [Term].[Total Term])\n",
    "\"\"\"\n",
    "\n",
    "with TM1Service(**config['tm1srv01']) as tm1:\n",
    "    loans_raw = tm1.cubes.cells.execute_mdx_dataframe(mdx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we assess the structure of the returned data.\n",
    "\n",
    "We print out number of rows and columns by calling the `shape` property on the loans_raw DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loans_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a closer look at the actual data.\n",
    "\n",
    "We print out the first 10 entries from the DataFrame with the `head` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is flat :-(\n",
    "\n",
    "The is an unpleasent sideeffect of the `execute_mdx_dataframe` method that we used to retrieve the data from the cube.\n",
    "Before we can plot it and analyse it further, we need to bring into a shape that is more convenient.\n",
    "\n",
    "_Sidenote:\n",
    "The execute_mdx_dataframe method is optimized for performance. It loses the original shape of the cube view when it retrieves data from TM1. To retrieve data in a pivot shape use the execute_mdx_dataframe_pivot method_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessing\n",
    "\n",
    "We need to rearrange the `loans_raw` DataFrame into something that is more convenient for consumption, down the road\n",
    "\n",
    "- Arrange Measures as seperate columns\n",
    "\n",
    "- Remove Value Column\n",
    "\n",
    "- Set new index in DataFrame based on Loan-Id\n",
    "\n",
    "The result of this operation we call `loans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = loans_raw.copy()\n",
    "\n",
    "# Arrange measures as columns\n",
    "for measure in (\"defaulted\", \"loan_amnt\", \"num_personal_inquiries\", \"int_rate\",\n",
    "                \"inquiries_in_last_12m\", \"mths_since_last_delinq\", \"mths_since_recent_bc_dlq\",\n",
    "                \"mths_since_recent_inq\"):\n",
    "    loans[measure] = loans.apply(lambda row: row[\"Value\"] if row[\"Loans Measure\"] == measure else None, axis=1)\n",
    "\n",
    "loans.drop(columns=[\"Value\"], inplace=True)\n",
    "loans.drop(columns=[\"Loans Measure\"], inplace=True)\n",
    "\n",
    "columns_to_remain = [\"LC Rating\", \"FICO Score\", \"Purpose\", \"State\", \"Time\", \"Income\", \"Income To Loan Ratio\",\n",
    "                 \"Home Ownership\", \"Delinquency Events\", \"Application Type\"]\n",
    "\n",
    "loans = loans.groupby([\"Loan\"] + columns_to_remain).sum()\n",
    "\n",
    "for column in columns_to_remain:\n",
    "    loans.reset_index(level=column, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets print out the `shape` of the resulting dataframe\n",
    "\n",
    "Number of entries should now be <= 20k (20k `HEAD` limit in the MDX query - Zero Suppression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print out the first 5 entries with the `head` method and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the DataFrame has a more convenient shape. We can use built-in pandas features to answer questions about our data \n",
    "\n",
    "1. What percentage of loans defaulted?\n",
    "2. What is the median loan size ?\n",
    "3. Correlation between FICO Score and Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['defaulted'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"loan_amnt\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"Income\"].corr(loans[\"FICO Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative correlation between income and credit-rating-score is unexpected. \n",
    "\n",
    "Perhaps because income is self provided by the application, and thus unreliable ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Exploratory Data Analysis and Feature Selection\n",
    "\n",
    "-----\n",
    "\n",
    "Now we want to use **pandas** and **plotly** to \n",
    "\n",
    "- Get a visual overview of the dataset we are dealing with \n",
    "- Select relevant features and remove irrelavant features from the dataframe\n",
    "\n",
    "The results of this section we will use later to build a machine learning model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 LC Rating\n",
    "\n",
    "_Assigned loan grade by Lending Club_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"LC Rating\"].unique()),\n",
    "    y=loans.groupby(by=\"LC Rating\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Rating\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost a linear relationship between the __LC Rating__ and the __Default Rate__. < 5 % for the best ratings until up to 70 % for the worst ratings.\n",
    "\n",
    "Towards the  lower end of the rating classes we see a higher variance between the bars. This is simply because there are less observations available in our dataset for G rated loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Purpose\n",
    "\n",
    "_A category provided by the borrower for the loan request_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"Purpose\"].unique()),\n",
    "    y=loans.groupby(by=\"Purpose\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Purpose\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaningful differences when we compare the default rates by the puporse for the Loan.\n",
    "\n",
    "We will feed this column to the ML model further down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 State\n",
    "\n",
    "_The state provided by the borrower in the loan application_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loans_by_state = loans.groupby(by=\"State\").mean()[\"defaulted\"] * 100\n",
    "loans_by_state.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant differencs by state! Let's visualize this in a map go a better overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [go.Choropleth(\n",
    "    autocolorscale=True,\n",
    "    locations=loans_by_state.index,\n",
    "    z=loans_by_state.values,\n",
    "    locationmode='USA-states',\n",
    "    marker=go.choropleth.Marker(\n",
    "        line=go.choropleth.marker.Line(\n",
    "            color='rgb(255,255,255)',\n",
    "            width=2\n",
    "        )),\n",
    "    colorbar=go.choropleth.ColorBar(\n",
    "        title=\"Defaults in %\")\n",
    ")]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=go.layout.Title(\n",
    "        text='Percentage of Loans that default'\n",
    "    ),\n",
    "    geo=go.layout.Geo(\n",
    "        scope='usa',\n",
    "        projection=go.layout.geo.Projection(type='albers usa'),\n",
    "        showlakes=True,\n",
    "        lakecolor='rgb(255, 255, 255)'),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant differences by state. \n",
    "\n",
    "Nebraska and Oklahoma > 30 % while Oregon has a rate of < 15 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Income To Loan Ratio\n",
    "\n",
    "_A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's first check if there a differences in the **Default Rate** on either side of the range\n",
    "\n",
    "Let's calculate the default rate for **Income To Loan Ratio** below 10 and greater than 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = loans.loc[loans['Income To Loan Ratio'] < 10]\n",
    "\n",
    "sum(df_temp[\"defaulted\"]) / len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.7 % default rate for borrowers with an **Income to Loan Ratio** below 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = loans.loc[loans['Income To Loan Ratio'] > 20]\n",
    "\n",
    "sum(df_temp[\"defaulted\"]) / len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23 % default rate for borrowers with an **Income to Loan Ratio** > 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from these two insights it seems the **Income To Loan Ratio** is a driver for the default rate.\n",
    "\n",
    "Now, to get the full picture we group the DataFrame by the **defaulted** column and then use the `descibe` method on the **Income To Loan Ratio** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.groupby('defaulted')['Income To Loan Ratio'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the mean **Income to Loan Ratio** for Fully paid loans was approx 18, while the mean **Income to Loan Ratio** for defaulted loans was approx 21. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Income\n",
    "\n",
    "_The self-reported annual income provided by the borrower during registration._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"Income\"].unique()),\n",
    "    y=loans.groupby(by=\"Income\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Income\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income** is provided by the borrower. It seems unreliable for three reasons\n",
    "\n",
    "1. Negative correlation between self provided income and official credit rating score\n",
    "2. very low default rate for income of 10k is implausible\n",
    "3. Spike in default rate for income of 120k seems implausible \n",
    "\n",
    "\n",
    "Let's remove it from the dataframe and not use down the road ! We remove the column with the `drop` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loans.drop(\"Income\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Application Type\n",
    "\n",
    "_Indicates whether the loan is an individual application or a joint application with two co-borrowers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"Application Type\"].unique()),\n",
    "    y=loans.groupby(by=\"Application Type\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Income\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default rate of the application types are quite different! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['Application Type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However only 0.6 % of the applications are joint. So it's not going to be of much help to help to predicts potential defaults among new loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Time\n",
    "\n",
    "_The month the loan was funded_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `describe` method on the column to get an overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loans['Time'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the MDX query we used, all loans are from Dec-2015. This Information is not relevant. Let's remove the column with the `drop` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.drop(\"Time\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 num_personal_inquiries\n",
    "\n",
    "_Number of personal finance inquiries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"num_personal_inquiries\"].unique()),\n",
    "    y=loans.groupby(by=\"num_personal_inquiries\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Number of Personal Finance Inquiries\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximately linear relationship between the default rate and the Number of Personal Finance Inquiries\n",
    "\n",
    "**Take away**: Applications with more Personal Finance Inquiries in the past have a higher default rate. \n",
    "\n",
    "100 % default rate for applications with 17 Finance Inquiries (probably just one or two records in the 20'000 loans we are looking at)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: More Data Processing\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate String columns to Numeric or Binary\n",
    "\n",
    "Unfortunately Classifier Implementations for Python can only consume numeric **features**, so we need to translate string columns (e.g. State, Rating, purpose) into numeric and binary columns.\n",
    "\n",
    "**FROM**\n",
    "\n",
    "| Loan  | State  |\n",
    "| :-: | :-: |\n",
    "| Loan 5 | CA |\n",
    "| Loan 8 | WA |\n",
    "\n",
    "\n",
    "**TO**\n",
    "\n",
    "| Loan  | State_CA | State_WA |\n",
    "| :-: | :-: | :-: |\n",
    "| Loan 5 | 1 | 0 |\n",
    "| Loan 8 | 0 | 1 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas library has a built-in functionality to translate categorical features into numeric features. It's called `get_dummies`\n",
    "\n",
    "The new DataFrame we will call `loans_numeric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loans_numeric = pd.get_dummies(\n",
    "    loans, \n",
    "    columns=['LC Rating', 'Home Ownership', 'Purpose', 'State', 'Application Type'],\n",
    "    drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_numeric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the resulting DataFrame we have the same amount of rows as before the transformation, but a lot more columns. This is the result we expected.\n",
    "\n",
    "By default Jupyter will not print all > 100 columns . The `...` represent the missing columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the `loans_numeric` DataFrame into **Features** (e.g. Income, Rating) and **Class** (Defaulted or Fully Paid). \n",
    "\n",
    "This is necessary, so that we can use the ML frameworks that python provides\n",
    "\n",
    "Naming of `X` and `y` is a convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loans_numeric.loc[:, loans_numeric.columns != \"defaulted\"]\n",
    "y = loans_numeric[\"defaulted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation between columns and default\n",
    "\n",
    "Now that all columns are numeric values we can calculate correlations between them\n",
    "\n",
    "_Sidenote:_\n",
    "- Values between 0 and 0.3 (0 and -0.3) indicate a weak positive (negative) linear relationship\n",
    "- Values between 0.3 and 0.7 (-0.3 and -0.7) indicate a moderate positive (negative) linear relationship\n",
    "- Values between 0.7 and 1.0 (-0.7 and -1.0) indicate a strong positive (negative) linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dep = pd.DataFrame()\n",
    "for col in X.columns:\n",
    "    linear_dep.loc[col, 'corr'] = X[col].corr(y)\n",
    "    \n",
    "linear_dep['abs_corr'] = abs(linear_dep['corr'])\n",
    "linear_dep.sort_values('abs_corr', ascending=False, inplace=True)\n",
    "\n",
    "linear_dep.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Fit And Evaluate Maschine Learning Model\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Scale data and split into test and training sets\n",
    "\n",
    "Before applying Machine Learning, we need to scale our data such that each feature has the same variance.\n",
    "\n",
    "This is necessary to avoid differences in weights for classifiers like KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape` of the DataFrame should not have been impacted by this operation! We are expecting the same amount of rows and columns in the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print out the first entry from the DataFrame and see if the values are roughly in the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data set into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before we `fit` and `apply` a ML model, let's split our original dataframe into a **test** and **training** data set\n",
    "This enables us to do to unbiased testing of the ML model later.\n",
    "\n",
    "To split the data randomly we are using the `train_test_split` method from the `sklearn` library.\n",
    "\n",
    "\n",
    "| Variable  | Content  |\n",
    "| :-: | :-: |\n",
    "| X_train | 80 % of the features |\n",
    "| X_test | 20 % of the features |\n",
    "| y_train | The results (Defaulted or Fully Paid) to the 80 %  |\n",
    "| y_test | the results (Defaulted or Fully Paid) to the 20 %  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 KNN (K Nearest Neighbors)\n",
    "\n",
    "`fit` a KNN model. \n",
    "\n",
    "We provide 1 arugment: `n_neighters` (number of neighbors).\n",
    "How to find the \"right\" value for this argument ? Try out different combinations and optimize for the desired outcome...\n",
    "\n",
    "_Sidenote: Fitting the ML model is just 2 lines of code!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the fitted KNN model on the test data set (`X_test`) with the `predict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate KNN results\n",
    "\n",
    "We use 3 Metrics to assess the quality of the model\n",
    "\n",
    "1. Confusion Matrix\n",
    "2. Classification Report\n",
    "3. ROC Curve\n",
    "\n",
    "These metrics are all implemented in `sklearn` so we don't need to write any custom code for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Calculate `confusion_matrix` from results on the test set and pretty-print visualization of confusion matrix as a `heatmap`\n",
    "\n",
    "\n",
    "| Corner  | Description  |\n",
    "| :-: | :-: |\n",
    "| **Top Left**  | True Positives: Loan default and we predicted default |\n",
    "| **Top Right** | False Negatives: Loan default and we predicted fine |\n",
    "| **Bottom Left** | False Positive: Loan fine and we predicted default |\n",
    "| **Bottom Right** | True Negatives: Loan fine and we predicted fine |\n",
    "\n",
    "\n",
    "\n",
    "Perfect precission would output a matrix with all values on the diagonal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[1, 0])\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    matrix, \n",
    "    annot=True, \n",
    "    fmt='d',\n",
    "    linewidths=.5,\n",
    "    cmap=\"YlGnBu\");\n",
    "\n",
    "# labels and titles\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "ax.xaxis.set_ticklabels(['Defaulted', 'Fully Paid'])\n",
    "ax.yaxis.set_ticklabels(['Defaulted', 'Fully Paid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "\n",
    "Calculate the  `classification_report`. This metric is based on the results from the confusion matrix.\n",
    "\n",
    "\n",
    "| Variable  | Description  |\n",
    "| :-: | :-: |\n",
    "| **precision**  | What percent of the predicted defaults were correct ? |\n",
    "| **recall** | What percent of the defaults did we catch ? |\n",
    "| **f1 score** | Weighted average over precission and recall |\n",
    "| **support** | number of records |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "knn_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "The dotted blue line is chance (flipping a coin). The orange line is our fitted classifier.\n",
    "\n",
    "The curve is plotted by executing the model with different parameters and plotting the **FPR** against the **TPR**.\n",
    "The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the model is.\n",
    "\n",
    "The area under the orange curve is called **AUC Score**. \n",
    "It is a generally accepted measure and convenient when comparing different models with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "probs = knn_classifier.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So - What’s a good AUC score ?\n",
    "There is no magic threshold. Higher is obviously better, but it is entirely application dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Random Forest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=20,\n",
    "    max_depth=100,\n",
    "    random_state=4)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "import seaborn as sns\n",
    "\n",
    "matrix = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[1, 0])\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(\n",
    "    matrix, \n",
    "    annot=True, \n",
    "    fmt='d',\n",
    "    linewidths=.5,\n",
    "    cmap=\"YlGnBu\");\n",
    "\n",
    "# labels and titles\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "ax.xaxis.set_ticklabels(['Defaulted', 'Fully Paid'])\n",
    "ax.yaxis.set_ticklabels(['Defaulted', 'Fully Paid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#rf_report = classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "probs = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the Random Forests provides better results according to the AUC measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot features importance\n",
    "\n",
    "the random forest can provide quantitative measures how relevant the features in our dataframe where.\n",
    "This makese the results more transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_importances = pd.DataFrame(\n",
    "    rf_classifier.feature_importances_,\n",
    "    index = X.columns,\n",
    "    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other\n",
    "\n",
    "Things that didn't make it into the demo.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Home Ownership\n",
    "\n",
    "The home ownership status provided by the borrower during registration. \n",
    "\n",
    "Possible values are: RENT, OWN, MORTGAGE, OTHER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = go.Bar(\n",
    "    x=sorted(loans[\"Home Ownership\"].unique()),\n",
    "    y=loans.groupby(by=\"Home Ownership\").mean()[\"defaulted\"].values)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title=\"Default Rate by Home Ownership Type\")\n",
    "\n",
    "data = [bar]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 FICO Score\n",
    "\n",
    "A credit score created by the Fair Isaac Corporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaulted = loans.loc[loans['defaulted'] == 1]['FICO Score']\n",
    "fine = loans.loc[loans['defaulted'] == 0]['FICO Score']\n",
    "\n",
    "hist1 = go.Histogram(\n",
    "    x=fine,\n",
    "    name=\"Fully Paid\"\n",
    ")\n",
    "hist2 = go.Histogram(\n",
    "    x=defaulted,\n",
    "    name=\"Defaulted\"\n",
    ")\n",
    "\n",
    "data = [hist1, hist2]\n",
    "layout = go.Layout(\n",
    "    barmode=\"stack\",\n",
    "    title=\"Histograms on FICO Score\")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "logrec_classifier = SGDClassifier(\n",
    "    loss='log', \n",
    "    max_iter=1000, \n",
    "    tol=1e-3, \n",
    "    random_state=1, \n",
    "    warm_start=True,\n",
    "    alpha=0.01, \n",
    "    penalty='l2')\n",
    "\n",
    "logrec_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logrec_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "matrix = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[1, 0])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print classification report\n",
    "\n",
    "**precision** - What percent of the predicted defaults that were correct ?\n",
    "\n",
    "**recall** – What percent of the defaults did we catch ?\n",
    "\n",
    "**f1 score** – Weighted average over precission and recall\n",
    "\n",
    "**support** - number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logrec_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "probs = logrec_classifier.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Dimension Reduction and Visualization in 2D\n",
    "\n",
    "_PCA is essentially a method that reduces the dimension of the feature space in such a way that new variables are orthogonal to each other (i.e. they are independent or not correlated)._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(X_train)\n",
    "principal_df = pd.DataFrame(\n",
    "    data = principal_components, \n",
    "    columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [go.Scatter(\n",
    "    x = principal_df[\"principal component 1\"],\n",
    "    y = principal_df[\"principal component 2\"],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        color = y_train.values\n",
    "        ),\n",
    "    )]\n",
    "\n",
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
